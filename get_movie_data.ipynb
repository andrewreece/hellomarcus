{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# we don't really need matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## these functions convert API json into friendly structure. \n",
    "## taken from http://stackoverflow.com/questions/956867/how-to-get-string-objects-instead-of-unicode-ones-from-json-in-python\n",
    "\n",
    "def _decode_list(data):\n",
    "    rv = []\n",
    "    for item in data:\n",
    "        if isinstance(item, unicode):\n",
    "            item = item.encode('utf-8')\n",
    "        elif isinstance(item, list):\n",
    "            item = _decode_list(item)\n",
    "        elif isinstance(item, dict):\n",
    "            item = _decode_dict(item)\n",
    "        rv.append(item)\n",
    "    return rv\n",
    "\n",
    "def _decode_dict(data):\n",
    "    rv = {}\n",
    "    for key, value in data.iteritems():\n",
    "        if isinstance(key, unicode):\n",
    "            key = key.encode('utf-8')\n",
    "        if isinstance(value, unicode):\n",
    "            value = value.encode('utf-8')\n",
    "        elif isinstance(value, list):\n",
    "            value = _decode_list(value)\n",
    "        elif isinstance(value, dict):\n",
    "            value = _decode_dict(value)\n",
    "        rv[key] = value\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RT API KEY\n",
    "api_key = # key removed for shared version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_dollarcomma(df, colset):\n",
    "    ## strip $ signs and commas from scraped data\n",
    "    nodollarcomma = re.compile('\\\\$|,')\n",
    "    for cname in df.columns.values[colset]:\n",
    "        df[cname] = [re.sub(nodollarcomma, '', str(val)) for val in df[cname]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for year: 2011\n",
      "Collecting data for year: 2012\n",
      "Collecting data for year: 2013\n",
      "Collecting data for year: 2014\n",
      "Collecting data for year: 2015\n",
      "Collecting data for year: 2016\n"
     ]
    }
   ],
   "source": [
    "## scraping www.boxofficemojo.com for movie titles and box office revenue\n",
    "#yr                  = 2010 #2010 #2011 #2012 #2013 #2014 #2015\n",
    "yrs        = [2011,2012,2013,2014,2015,2016]\n",
    "ct         = 0\n",
    "cols       = ['title','year','tg','tg_adj','op','op_adj','tg_theaters','op_theaters','opdate','cldate','days','budget']\n",
    "num_movies = 2500\n",
    "num_cols   = len(cols)\n",
    "init       = np.zeros((num_movies,num_cols))\n",
    "df         = pd.DataFrame(data=init,columns=cols)    \n",
    "\n",
    "for yr in yrs:\n",
    "    url_page_numbers    = [1,2,3,4,5] if yr < 2016 else [1,2]\n",
    "    \n",
    "    print 'Collecting data for year: '+str(yr)\n",
    "    \n",
    "    ## open mojo URL, scrape everything, parse in beautiful soup\n",
    "    for pnum in url_page_numbers:\n",
    "\n",
    "        url      = 'http://www.boxofficemojo.com/yearly/chart/'\n",
    "        opts     = {'page':pnum,'view':'releasedate','view2':'domestic','yr':yr,'p':'.htm'}\n",
    "        query    = requests.get(url,params=opts).text.encode('utf8')\n",
    "        soupdata = soup(query)\n",
    "\n",
    "        ## these regex patterns are based on looking at the relevant HTML source code\n",
    "        for cell in soupdata.find_all('td'):\n",
    "            pattern_title = cell.find_all(href=re.compile('movies\\\\/\\\\?id'))\n",
    "            pattern_tg = cell.find_all('b',text=re.compile('\\\\$\\d'))\n",
    "            pattern_tg_theaters = cell.find_all('b',text=re.compile('\\\\$\\d'))\n",
    "\n",
    "            ## save movie title\n",
    "            if pattern_title:\n",
    "                #print 'MOVIE'\n",
    "                if len(list(cell.descendants)) < 5:\n",
    "\n",
    "                    url2 = \"http://www.boxofficemojo.com/\"+cell.b.font.a['href']\n",
    "                    try:\n",
    "                        query2    = requests.get(url2).text.encode('utf8')\n",
    "                    except Exception,e:\n",
    "                        print \"Failed on {}\".format(url2)\n",
    "                        pass\n",
    "                    soupdata2 = soup(query2)\n",
    "                    ## go into individual movie pages to get production budget info\n",
    "                    ## note: this doesn't exist for all movies, especially low-budget films\n",
    "                    for cell2 in soupdata2.find_all('td',valign='top'):#text=re.compile('Production\\sBudget')):\n",
    "                        pattern_budget = cell2.find_all(text=re.compile('Production Budget'))\n",
    "                        if pattern_budget:\n",
    "                            if cell2.b.text[0] == '$':\n",
    "                                temp = cell2.b.text.split(\" \")\n",
    "                                if len(temp) > 1:\n",
    "                                    if temp[1] == \"million\":\n",
    "                                        scaleup = 1000000\n",
    "                                    elif temp[1] == \"thousand\":\n",
    "                                        scaleup = 1000\n",
    "                                    budget = str(float(temp[0][1:]) * scaleup)\n",
    "                                else:\n",
    "                                    budget = temp[0]\n",
    "                                df.ix[ct,'budget'] = budget\n",
    "                                break\n",
    "                df.ix[ct,'title'] = pattern_title[0].text\n",
    "\n",
    "            ## save revenue, theater, and date info\n",
    "            if ((len(pattern_tg)==1) and # sometimes this pattern brings back a ton of values\n",
    "                (cell.next_sibling.font.text!='N/A') and\n",
    "                (cell.next_sibling.next_sibling.font.text!='N/A') and\n",
    "                (cell.next_sibling.next_sibling.next_sibling.font.text!='N/A')): \n",
    "                    #print 'TOTAL GROSS'\n",
    "                    #print pattern_tg[0].text\n",
    "                    df.ix[ct,'tg']          = pattern_tg[0].text\n",
    "                    df.ix[ct,'tg_theaters'] = cell.next_sibling.font.text\n",
    "                    df.ix[ct,'op']          = cell.next_sibling.next_sibling.font.text\n",
    "                    df.ix[ct,'op_theaters'] = cell.next_sibling.next_sibling.next_sibling.font.text\n",
    "                    df.ix[ct,'opdate']      = cell.next_sibling.next_sibling.next_sibling.next_sibling.font.text\n",
    "                    df.ix[ct,'cldate']      = cell.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.font.text\n",
    "                    df.ix[ct,'year']        = yr\n",
    "                    \n",
    "                    ct += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = df.budget==0\n",
    "df.ix[mask,'budget'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = strip_dollarcomma(df, [2,4,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## find the last row of usable data and cut off the rest \n",
    "## (i made the dataframe bigger than it needs to be)\n",
    "\n",
    "row_cutoff = False\n",
    "\n",
    "for i,cl in enumerate(df.cldate):\n",
    "    try:\n",
    "        a = cl[0]\n",
    "    except:\n",
    "        row_cutoff = i-1 # number of available movies for a given year\n",
    "        break\n",
    "\n",
    "if not row_cutoff:\n",
    "    row_cutoff = df.shape[0]+1\n",
    "## create DATA_ variable (just to maintain variable naming convention)\n",
    "DATA_mojo = df.ix[0:row_cutoff,:].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## add years to dates, compute number of days movie played in total\n",
    "## if movie is still playing, compute up to current date\n",
    "today = time.strftime('%m/%d/%Y') \n",
    "\n",
    "for i,cl in enumerate(DATA_mojo.cldate):\n",
    "    #print DATA_mojo.title[i]\n",
    "    op = DATA_mojo.opdate[i]\n",
    "    yr = int(DATA_mojo.year[i])\n",
    " \n",
    "    ## mojo sets the closing date as '-' for movies that are still playing\n",
    "    ## this first part of the if/else is for movies that are NOT still playing\n",
    "    if (str(cl[0])!='-'):\n",
    "        try:\n",
    "            opd = datetime.strptime(op, '%m/%d')\n",
    "            cld = datetime.strptime(DATA_mojo.cldate[i], '%m/%d')\n",
    "        except: # leap year bug - at first there are no years assigned so it goes back to 1970\n",
    "            if op=='2/29':\n",
    "                opd = datetime.strptime('2/28', '%m/%d')\n",
    "                cld = datetime.strptime(DATA_mojo.cldate[i], '%m/%d')\n",
    "            elif DATA_mojo.cldate[i]=='2/29':\n",
    "                opd = datetime.strptime(op, '%m/%d')\n",
    "                cld = datetime.strptime('2/28', '%m/%d')\n",
    "        ## do the open and close dates cross over a year boundary?\n",
    "        if (opd-cld).days > 0:\n",
    "            DATA_mojo.cldate[i] += '/'+str(yr+1) \n",
    "            DATA_mojo.opdate[i] += '/'+str(yr) \n",
    "        else:\n",
    "            DATA_mojo.cldate[i] += '/'+str(yr)\n",
    "            DATA_mojo.opdate[i] += '/'+str(yr)\n",
    "    ## this section deals with movies that ARE still playing\n",
    "    else:\n",
    "        temp = DATA_mojo.opdate[i]\n",
    "        ## there is at least one 2015 movie which claims to have opened on a leap day! (which can't be.)\n",
    "        if DATA_mojo.opdate[i][0:5] =='2/29':\n",
    "            DATA_mojo.opdate[i] = '2/28'\n",
    "        DATA_mojo.cldate[i] = today\n",
    "        DATA_mojo.opdate[i] += '/'+str(int(yr))\n",
    "\n",
    "    try:\n",
    "        opd = datetime.strptime(DATA_mojo.opdate[i], '%m/%d/%Y')\n",
    "    \n",
    "        cld = datetime.strptime(DATA_mojo.cldate[i], '%m/%d/%Y')\n",
    "        DATA_mojo.days[i] = abs((opd-cld).days)\n",
    "    except Exception, e:\n",
    "        print\n",
    "        print 'problem!'\n",
    "        print DATA_mojo.opdate[i]\n",
    "        print str(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>tg</th>\n",
       "      <th>tg_adj</th>\n",
       "      <th>op</th>\n",
       "      <th>op_adj</th>\n",
       "      <th>tg_theaters</th>\n",
       "      <th>op_theaters</th>\n",
       "      <th>opdate</th>\n",
       "      <th>cldate</th>\n",
       "      <th>days</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Deathly Hallows Part 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>381011219</td>\n",
       "      <td>659.760</td>\n",
       "      <td>169189427</td>\n",
       "      <td>38671.869</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>7/15/2011</td>\n",
       "      <td>11/24/2011</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers: Dark of the Moon</td>\n",
       "      <td>2011</td>\n",
       "      <td>352390543</td>\n",
       "      <td>813.219</td>\n",
       "      <td>97852865</td>\n",
       "      <td>23936.611</td>\n",
       "      <td>4088</td>\n",
       "      <td>4088</td>\n",
       "      <td>6/29/2011</td>\n",
       "      <td>10/13/2011</td>\n",
       "      <td>106</td>\n",
       "      <td>195000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Twilight Saga: Breaking Dawn Part 1</td>\n",
       "      <td>2011</td>\n",
       "      <td>281287133</td>\n",
       "      <td>713.199</td>\n",
       "      <td>138122261</td>\n",
       "      <td>34011.884</td>\n",
       "      <td>4066</td>\n",
       "      <td>4061</td>\n",
       "      <td>11/18/2011</td>\n",
       "      <td>2/23/2012</td>\n",
       "      <td>97</td>\n",
       "      <td>110000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hangover Part II</td>\n",
       "      <td>2011</td>\n",
       "      <td>254464305</td>\n",
       "      <td>618.232</td>\n",
       "      <td>85946294</td>\n",
       "      <td>23774.908</td>\n",
       "      <td>3675</td>\n",
       "      <td>3615</td>\n",
       "      <td>5/26/2011</td>\n",
       "      <td>9/15/2011</td>\n",
       "      <td>112</td>\n",
       "      <td>80000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>2011</td>\n",
       "      <td>241071802</td>\n",
       "      <td>438.593</td>\n",
       "      <td>90151958</td>\n",
       "      <td>21697.222</td>\n",
       "      <td>4164</td>\n",
       "      <td>4155</td>\n",
       "      <td>5/20/2011</td>\n",
       "      <td>9/29/2011</td>\n",
       "      <td>132</td>\n",
       "      <td>250000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  year         tg   tg_adj  \\\n",
       "0  Harry Potter and the Deathly Hallows Part 2  2011  381011219  659.760   \n",
       "1               Transformers: Dark of the Moon  2011  352390543  813.219   \n",
       "2      The Twilight Saga: Breaking Dawn Part 1  2011  281287133  713.199   \n",
       "3                         The Hangover Part II  2011  254464305  618.232   \n",
       "4  Pirates of the Caribbean: On Stranger Tides  2011  241071802  438.593   \n",
       "\n",
       "          op     op_adj tg_theaters op_theaters      opdate      cldate  days  \\\n",
       "0  169189427  38671.869        4375        4375   7/15/2011  11/24/2011   132   \n",
       "1   97852865  23936.611        4088        4088   6/29/2011  10/13/2011   106   \n",
       "2  138122261  34011.884        4066        4061  11/18/2011   2/23/2012    97   \n",
       "3   85946294  23774.908        3675        3615   5/26/2011   9/15/2011   112   \n",
       "4   90151958  21697.222        4164        4155   5/20/2011   9/29/2011   132   \n",
       "\n",
       "        budget  \n",
       "0          NaN  \n",
       "1  195000000.0  \n",
       "2  110000000.0  \n",
       "3   80000000.0  \n",
       "4  250000000.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create adjusted total and opening weekend gross revenue\n",
    "## tg_adj = tg / (tg_theaters * days) = dollars per theater per day\n",
    "## op_adj = op / (op_theaters)        = dollars per theater\n",
    "\n",
    "DATA_mojo.op_adj = np.round(np.divide(DATA_mojo.op.values.astype(float),\n",
    "                                      DATA_mojo.op_theaters.values.astype(float)),3)\n",
    "DATA_mojo.tg_adj = np.round(np.divide(DATA_mojo.tg.values.astype(float), \n",
    "                                      DATA_mojo.tg_theaters.values.astype(float)*DATA_mojo.days.values.astype(float)),3)\n",
    "\n",
    "DATA_mojo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## sometimes (notably in 2010 data), movie titles will have non-ASCII chars (eg.'è')\n",
    "## 'è' is the only exception i found from 2010-2015, so we replace it with 'e' here\n",
    "## i checked RT and they do the same thing with their movie titles.\n",
    "for i,t in enumerate(DATA_mojo.title):\n",
    "    try:\n",
    "        if re.search('è',t.encode('utf8')):\n",
    "            DATA_mojo.title[i] = re.sub('è','e',t.encode('utf8'))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_mojo.title = DATA_mojo.title.apply(lambda x : x.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write scraped mojo movie data to csv\n",
    "\n",
    "DATA_mojo.to_csv(\"lda-data/mojo/mojoall.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section is pre-processing before querying Rotten Tomatoes API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_subtitles(df):\n",
    "    ## strip movie strings of parenthetical titles and subtitles (ie. The Movie Title: the subtitle)\n",
    "    pattern   = re.compile('\\\\(.+\\\\)')\n",
    "    names = [re.sub(pattern,'',mov).encode('utf8') for mov in df.title]\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_mojo.title = strip_subtitles(DATA_mojo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## replace whitespace with + for URI encoding\n",
    "pattern      = re.compile('\\s(\\S)')\n",
    "namesURI = [re.sub(pattern,'+\\\\1',mov).encode('utf8').strip().lower() for mov in DATA_mojo.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## replace colons with %3A URI encoding (not sure if this is necessary)\n",
    "pattern = re.compile(':')\n",
    "namesURI2 = [re.sub(pattern,'%3A',mov).encode('utf8') for mov in namesURI]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query RT review URLs using movie names from Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_mojo['revurl']       = None\n",
    "DATA_mojo['critscore']    = None\n",
    "DATA_mojo['critrate']     = None\n",
    "DATA_mojo['audiscore']    = None\n",
    "DATA_mojo['audirate']     = None\n",
    "DATA_mojo['genres']       = None\n",
    "DATA_mojo['id_rt']        = None\n",
    "DATA_mojo['id_imdb']      = None\n",
    "DATA_mojo['mpaa']         = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_level2_param(x,level1,level2):\n",
    "    try:\n",
    "        imdb = x[level1][level2]\n",
    "        return imdb\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrew/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MATCH: TITLE: harry potter and the deathly hallows - part 2 | YEAR: 2011\n",
      "harry potter and the deathly hallows part 2 != harry potter and the deathly hallows - part 2\n",
      "NO MATCH: TITLE: twilight saga: breaking dawn part 1 | YEAR: 2011\n",
      "the twilight saga: breaking dawn part 1 != twilight saga: breaking dawn part 1\n",
      "NO MATCH: TITLE: the twilight saga: breaking dawn part 1 (extended edition) | YEAR: 2013\n",
      "the twilight saga: breaking dawn part 1 != the twilight saga: breaking dawn part 1 (extended edition)\n",
      "NO MATCH: TITLE: twilight saga double feature: eclipse and breaking dawn part 1 | YEAR: 2012\n",
      "the twilight saga: breaking dawn part 1 != twilight saga double feature: eclipse and breaking dawn part 1\n",
      "NO MATCH: TITLE: mission: impossible ghost protocol | YEAR: 2011\n",
      "mission: impossible - ghost protocol != mission: impossible ghost protocol\n",
      "NO MATCH: TITLE: i am thor | YEAR: 2015\n",
      "thor != i am thor\n",
      "MATCH FOUND: thor | YEAR: 2011\n",
      "NO MATCH: TITLE: the great gilly hopkins | YEAR: 2016\n",
      "hop != the great gilly hopkins\n",
      "MATCH FOUND: hop | YEAR: 2011\n",
      "NO MATCH: TITLE: ktown cowboys | YEAR: 2016\n",
      "cowboys & aliens != ktown cowboys\n",
      "MATCH FOUND: cowboys & aliens | YEAR: 2011"
     ]
    }
   ],
   "source": [
    "## get RT review URLs for all movies from DATA_mojo\n",
    "movielist = namesURI2\n",
    "RESULTS   = np.empty(len(movielist),dtype=\"object\")\n",
    "\n",
    "for n,movie in enumerate(movielist[0:]):\n",
    "    yr = DATA_mojo.year[n]\n",
    "    if n%5==0:\n",
    "        time.sleep(1) # RT only allows 5 API requests/second\n",
    "     \n",
    "    url             = 'http://api.rottentomatoes.com/api/public/v1.0/movies.json?q='+movie\n",
    "    opts            = {'page_limit':4,'page':1,'apikey':api_key}\n",
    "    query           = requests.get(url,params=opts).text\n",
    "    try:\n",
    "        DATA_           = json.loads(query, object_hook=_decode_dict)\n",
    "    except:\n",
    "        print query\n",
    "        break\n",
    "    # 'nomatch' is for reporting only - when we loop through results and don't find something\n",
    "    # at first, if we eventually do find it we make note of this fact in the printout.\n",
    "    nomatch = False \n",
    "    \n",
    "    for x in DATA_['movies']:\n",
    "        \n",
    "        rt_yr       = x['year']\n",
    "        rt_title    = x['title'].strip().lower()\n",
    "        mj_title    = DATA_mojo.title[n].strip().lower()\n",
    "        \n",
    "        # sometimes the first hit is an old movie. also we need to strip and lowercase for matching.\n",
    "        if ((rt_yr==yr)or(rt_yr==yr+1)) and (rt_title==mj_title) and (float(x['ratings']['critics_score'])>0) and (float(x['ratings']['audience_score'])>0):\n",
    "            RESULTS[n]                = x['links']['reviews']\n",
    "            DATA_mojo['revurl'][n]    = x['links']['reviews']\n",
    "            DATA_mojo['critscore'][n] = x['ratings']['critics_score']\n",
    "            DATA_mojo['critrate'][n]  = get_level2_param(x,'ratings','critics_rating')\n",
    "            DATA_mojo['audiscore'][n] = x['ratings']['audience_score']\n",
    "            DATA_mojo['audirate'][n]  = get_level2_param(x,'ratings','audience_rating')\n",
    "        \n",
    "            DATA_mojo['id_rt'][n]     = x['id']\n",
    "            DATA_mojo['id_imdb'][n]   = get_level2_param(x,'alternate_ids','imdb')\n",
    "            DATA_mojo['mpaa'][n]      = x['mpaa_rating']\n",
    "            \n",
    "            if nomatch:\n",
    "                print 'MATCH FOUND: '+rt_title+' | YEAR: '+str(rt_yr)\n",
    "            break\n",
    "        else:\n",
    "            nomatch = True\n",
    "            print 'NO MATCH: TITLE: '+rt_title+' | YEAR: '+str(rt_yr)\n",
    "            print mj_title+' != '+rt_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get rid of duplicate titles (there are only a few)\n",
    "DATA_mojo.drop(DATA_mojo.index[np.where(DATA_mojo.duplicated(subset='title'))[0]],0,inplace=True)\n",
    "DATA_mojo.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_mojo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## drop the movies we couldn't find reviews for\n",
    "mask = []\n",
    "for d in DATA_mojo['revurl']:\n",
    "    mask.append((d is not None))\n",
    "mojo2 = DATA_mojo[mask].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n,rtid in enumerate(mojo2['id_rt']):\n",
    "    if n%5==0:\n",
    "        time.sleep(1) # RT only allows 5 API requests/second\n",
    "   \n",
    "    url   = 'http://api.rottentomatoes.com/api/public/v1.0/movies/{rtid}.json'.format(rtid=str(rtid))\n",
    "    opts  = {'apikey':api_key}\n",
    "    query = requests.get(url,params=opts).text\n",
    "    DATA_ = json.loads(query, object_hook=_decode_dict)\n",
    "\n",
    "    mojo2['genres'][n] = DATA_['genres'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull first 20 RT review blurbs per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mojo2.revurl = mojo2.revurl.apply(lambda x: \"http:\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "## take parsed URI-format movie titles and pull reviews from RT\n",
    "N            = mojo2.shape[0]\n",
    "K            = 20\n",
    "DATA_reviews = np.empty((N,K),dtype='object')\n",
    "\n",
    "for n,url in enumerate(mojo2.revurl):\n",
    "    if n%100==0:\n",
    "        print n       # report iteration number\n",
    "    if n%5==0:\n",
    "        time.sleep(1) # RT only allows 5 API requests/second\n",
    "        \n",
    "    opts  = {'apikey':api_key}\n",
    "    query = requests.get(url, params=opts).text\n",
    "    DATA_ = json.loads(query, object_hook=_decode_dict)\n",
    "\n",
    "    for k,x in enumerate(DATA_['reviews']):\n",
    "        DATA_reviews[n,k] = x['quote']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Believe has no review.\n",
      "Busco Novio Para Mi Mujer has no review.\n"
     ]
    }
   ],
   "source": [
    "## look for movies with no reviews, and exclude them from the final list\n",
    "mask = []\n",
    "\n",
    "DATA_reviews_cleaned = []\n",
    "DATA_titles_cleaned  = []\n",
    "for i,rev in enumerate(DATA_reviews):\n",
    "    reviewed=False\n",
    "    \n",
    "    for r in rev:\n",
    "        if not r==None:\n",
    "            reviewed=True\n",
    "    if not reviewed:\n",
    "        print mojo2.title[i]+' has no review.'\n",
    "        mask.append(False)\n",
    "    else:\n",
    "        DATA_reviews_cleaned.append(rev)\n",
    "        DATA_titles_cleaned.append(mojo2.title[i])\n",
    "        mask.append(True)\n",
    "\n",
    "mojo3 = mojo2[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write output to csv\n",
    "np.savetxt(\"lda-data/reviews/reviewsall.csv\", DATA_reviews_cleaned, fmt='%s', delimiter=\"__\")\n",
    "np.savetxt(\"lda-data/movietitles/titlesall.csv\", DATA_titles_cleaned, fmt=\"%s\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mojo3.to_csv(\"lda-data/mojo/mojoall.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
